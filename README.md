# ML, DL, and NLP Portfolio

This repository showcases some of my work in machine learning, deep learning, and natural language processing.

## Index

- **HF Dataset - SciEntsBank:** Loads the SciEntsBank dataset from its original XML files and converts it into a Hugging Face dataset for NLP tasks.
- **HF Dataset - Beetle:** Loads the Beetle dataset from its original XML files and converts it into a Hugging Face dataset for NLP tasks.
- **LLM - Text Classification:** Demonstrates a minimal example of fine-tuning a pretrained large language model (LLM), such as RoBERTa Large, on a task-specific dataset like SciEntsBank for Automated Short-Answer Grading (multi-class classification) using the Hugging Face library. This notebook is outlined for beginners to provide an easy-to-follow high-level overview of the fine-tuning process.
- **LLM - Advanced Text Classification:** Examples of some advanced techniques in text classification  for BERT-like LLMs.
- **LLM - Transfer Learning:** Demonstrates leveraging transfer learning with a pre-trained LLM RoBERTa Large that is already fine-tuned on the MNLI corpus, further fine-tuning it on a related corpus like SNLI, before preparing it for task-specific fine-tuning, such as for text classification.
- **RL DDQN - Energy-Constrained Path Planning:** Demonstrates an implementation of Deep Double Q-Learning (DDQN) to solve an energy-constrained path planning problem, where an agent learns to navigate a grid-based environment efficiently, optimizing energy consumption while utilizing charging stations to recharge its battery.

# License

This project is licensed under the [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0) - see the [LICENSE](LICENSE) file for details.

**Synopsis:** Researchers and developers are welcome to **use, modify, and distribute** any code or content of this repository, provided that the original author, **Nazmul Kazi, is appropriately credited** and any modifications are clearly indicated, in accordance with the terms of the Apache License 2.0.