{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ee4a20",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5577d5b",
   "metadata": {},
   "source": [
    "This notebook demonstrates some advanced techniques in text classification for BERT-like LLMs. The examples in this notebook are based on a project aimed at detecting misconceptions in student responses, which is a challenging and complex NLP task. We will use a private dataset, carefully developed for this research, in some of the examples. Since the dataset is not publicly available, we have included a section that presents actual samples and provides an overview of its structure. For more details on this research and the dataset, please refer to my [thesis](https://digitalcommons.unf.edu/etd/1234/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c1965",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc983b",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "The data is collected from a quiz administered on the fifth day of an introductory circuit analysis course. In the quiz, students are asked to determine and explain the values of each element in an electrical circuit, given that the value of a specific element has changed. Student answers are provided in paragraph format and include domain-specific terminology, abbreviations, acronyms, nomenclature, and equations.\n",
    "\n",
    "Seven distinct misconceptions have been identified by experts in the student answers. In most cases, misconceptions are identified from a single sentence. However, some misconceptions exhibit inter-sentence dependencies, making them undetectable when sentences are analyzed independently. These misconceptions can only be identified when a sentence is examined in the context of a preceding sentence. As a result, the student answers are annotated at the sentence level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cca4e5",
   "metadata": {},
   "source": [
    "### Example of Student Answer\n",
    "\n",
    "Vs is an ideal component, so changing R2 will not affect it. R1 is in series with iR23 so changing R2 will also not affect the power associated with it. R3 will slowly have a decrease in power as R2's resistance goes to 0, with R2 at zero coinciding with no power in R3. R2 will increase in power, because the current is going to increase with a decrease in resistance. So Vs is the same, R1 is the same, R2 is larger and R3 is smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d3eb9",
   "metadata": {},
   "source": [
    "### Dataset Structure\n",
    "\n",
    "The following rows correspond to the student responses above. The question and reference answer are truncated for brevity. The `hypothesis` column indicates the sentence under evaluation, while the `context` column contains the preceding sentences. In this student answer, the second sentence (`id = 2`) contains a misconception. The label `none` represents no misconception.\n",
    "\n",
    "<table>\n",
    "   <thead>\n",
    "      <tr>\n",
    "         <th style=\"width: 1%; text-align: center;\">id</th>\n",
    "         <th style=\"width: 15%; text-align: center;\">question</th>\n",
    "         <th style=\"width: 15%; text-align: center;\">reference_answer</th>\n",
    "         <th style=\"width: 35%; text-align: center;\">context</th>\n",
    "         <th style=\"width: 35%; text-align: center;\">hypothesis</th>\n",
    "         <th style=\"width: 1%; text-align: center;\">label</th>\n",
    "      </tr>\n",
    "   </thead>\n",
    "   <tbody>\n",
    "      <tr>\n",
    "         <td>1</td>\n",
    "         <td>Resistors R1 and R2 are...</td>\n",
    "         <td>As the resistance of R2...</td>\n",
    "         <td></td>\n",
    "         <td>Vs is an ideal component, so changing R2 will not affect it.</td>\n",
    "         <td>none</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td>2</td>\n",
    "         <td>Resistors R1 and R2 are...</td>\n",
    "         <td>As the resistance of R2...</td>\n",
    "         <td>Vs is an ideal component, so changing R2 will not affect it.</td>\n",
    "         <td>R1 is in series with iR23 so changing R2 will also not affect the power associated with it.</td>\n",
    "         <td>SM</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td>3</td>\n",
    "         <td>Resistors R1 and R2 are...</td>\n",
    "         <td>As the resistance of R2...</td>\n",
    "         <td>Vs is an ideal component, so changing R2 will not affect it. R1 is in series with iR23 so changing R2 will also not affect the power associated with it.</td>\n",
    "         <td>R3 will slowly have a decrease in power as R2's resistance goes to 0, with R2 at zero coinciding with no power in R3.</td>\n",
    "         <td>none</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td>4</td>\n",
    "         <td>Resistors R1 and R2 are...</td>\n",
    "         <td>As the resistance of R2...</td>\n",
    "         <td>Vs is an ideal component, so changing R2 will not affect it. R1 is in series with iR23 so changing R2 will also not affect the power associated with it. R3 will slowly have a decrease in power as R2's resistance goes to 0, with R2 at zero coinciding with no power in R3.</td>\n",
    "         <td>R2 will increase in power, because the current is going to increase with a decrease in resistance.</td>\n",
    "         <td>none</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "         <td>5</td>\n",
    "         <td>Resistors R1 and R2 are...</td>\n",
    "         <td>As the resistance of R2...</td>\n",
    "         <td>Vs is an ideal component, so changing R2 will not affect it. R1 is in series with iR23 so changing R2 will also not affect the power associated with it. R3 will slowly have a decrease in power as R2's resistance goes to 0, with R2 at zero coinciding with no power in R3. R2 will increase in power, because the current is going to increase with a decrease in resistance.</td>\n",
    "         <td>So Vs is the same, R1 is the same, R2 is larger and R3 is smaller.</td>\n",
    "         <td>none</td>\n",
    "      </tr>\n",
    "   </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c0110e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dataset = DatasetDict.load_from_disk('private_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571408b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'reference_answer', 'context', 'hypothesis', 'label'],\n",
      "        num_rows: 1275\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['id', 'question', 'reference_answer', 'context', 'hypothesis', 'label'],\n",
      "        num_rows: 204\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'reference_answer', 'context', 'hypothesis', 'label'],\n",
      "        num_rows: 208\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78b09e",
   "metadata": {},
   "source": [
    "# Input Engineering\n",
    "\n",
    "We frame misconception detection as a Recognizing Textual Entailment (RTE) task, where the goal is to determine whether a hypothesis entails a premise. In our dataset, each example consists of a question, reference answer, context, and hypothesis. Here, the reference answer serves as the premise. In our previous research, we have showed that the question provides valuable information for the model, while the context is essential for detecting misconceptions that involve inter-sentence dependencies. However, BERT-like LLMs are designed to process single or paired inputs, necessitating a strategy to integrate all four components into an input pair. Simply combining the question, reference answer, and context into the premise is problematic, as incorrect information in the context could conflict with the reference answer and confuse the model. Therefore, we must combine the context with the hypothesis while ensuring a clear separation. We concatenate the context with the hypothesis using a single newline character, as neither the context nor the hypothesis contains it. We combine the question and the reference answer with a single space, instead of a newline character, to present them as a single continuous text to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c3679",
   "metadata": {},
   "source": [
    "### Pre-defined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8508c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'FacebookAI/roberta-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45913f5",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fe493d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100% [====================] 25.0/25.0 [00:00<00:00, 8.34kB/s]\n",
      "vocab.json: 100% [====================] 899k/899k [00:00<00:00, 8.79MB/s]\n",
      "merges.txt: 100% [====================] 456k/456k [00:00<00:00, 16.0MB/s]\n",
      "tokenizer.json: 100% [====================] 1.36M/1.36M [00:00<00:00, 4.86MB/s]"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd3830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization_function(examples):\n",
    "    # Integrate components/columns into input pairs\n",
    "    if examples.__class__.__name__ == 'LazyBatch': # batched examples\n",
    "        premises = [f'{a} {b}' for a, b in zip(examples['question'], examples['reference_answer'])]\n",
    "        hypotheses = [f'{a}\\n{b}' for a, b in zip(examples['context'], examples['hypothesis'])]\n",
    "    else: # single example\n",
    "        premises = f'{examples[\"question\"]} {examples[\"reference_answer\"]}'\n",
    "        hypotheses = f'{examples[\"context\"]}\\n{examples[\"hypothesis\"]}'\n",
    "    \n",
    "    # Tokenize\n",
    "    return tokenizer(text = premises, text_pair = hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393de946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map: 100% [====================] 1275/1275 [00:00<00:00, 1737.89 examples/s]\n",
      "Map: 100% [====================] 204/204 [00:00<00:00, 756.34 examples/s]\n",
      "Map: 100% [====================] 208/208 [00:00<00:00, 1917.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(tokenization_function, batched = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e93a90",
   "metadata": {},
   "source": [
    "# Adding Domain-specific Words to LLMs\n",
    "\n",
    "Student answers in our dataset contain domain-specific terminology, abbreviations, acronyms, and nomenclature. Some of these words are unknown to models like RoBERTa. In such cases, the tokenizer either splits these words incorrectly or maps them to `[unk]` (i.e., unknown), causing the model to misinterpret or ignore them. Depending on their frequency, they can introduce noise into the model input, negatively impacting its performance. In this section, we demonstrate how to add domain-specific words to both the tokenizer and the model before fine-tuning to ensure these terms are tokenized and interpreted correctly. The process of filtering domain-specific words from text is not included in this example, as it is complex and, at present, no library provides out-of-the-box tools that would allow me to summarize the process in a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2f263",
   "metadata": {},
   "source": [
    "### Pre-defined Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bc48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import AddedToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c22bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'FacebookAI/roberta-large'\n",
    "\n",
    "# List of domain-specific words tokenized\n",
    "domain_specific_tokens = [\n",
    "    'KVL',\n",
    "    AddedToken(\"Kirchhoff\", single_word=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2aecce",
   "metadata": {},
   "source": [
    "### Extending Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de273693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17008ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100% [====================] 25.0/25.0 [00:00<00:00, 8.34kB/s]\n",
      "vocab.json: 100% [====================] 899k/899k [00:00<00:00, 8.79MB/s]\n",
      "merges.txt: 100% [====================] 456k/456k [00:00<00:00, 16.0MB/s]\n",
      "tokenizer.json: 100% [====================] 1.36M/1.36M [00:00<00:00, 4.86MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f678a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'ir', 'ch', 'hoff', \"'s\", 'ĠK', 'VL', 'Ġstates', 'Ġthe', 'Ġsum', 'Ġof', 'Ġvolt', 'ages', 'Ġin', 'Ġa', 'Ġloop', 'Ġis', 'Ġzero', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization before adding domain-specific tokens\n",
    "print(tokenizer.tokenize(\"Kirchhoff's KVL states the sum of voltages in a loop is zero.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea4a155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of domain-specific tokens: 2\n",
      "Number of added tokens: 2\n",
      "Original vocabulary size: 50,265\n",
      "Extended vocabulary size: 50,267"
     ]
    }
   ],
   "source": [
    "# Log the number of domain-specific tokens in the list\n",
    "print(f'Number of domain-specific tokens: {len(domain_specific_tokens):,}')\n",
    "\n",
    "# Add domain-specific tokens to the tokenizer's vocabulary.\n",
    "# Tokens that do not already exist in the current vocabulary will be added.\n",
    "# New tokens will be appended to the end of the vocabulary but they will be\n",
    "# kept isolated from the original vocabulary.\n",
    "num_added_tokens = tokenizer.add_tokens(domain_specific_tokens)\n",
    "print(f'Number of added tokens: {num_added_tokens:,}')\n",
    "\n",
    "# Log original vocabulary size\n",
    "print(f'Original vocabulary size: {tokenizer.vocab_size:,}')\n",
    "\n",
    "# Log vocabulary size after adding domain-specific words\n",
    "print(f'Extended vocabulary size: {len(tokenizer):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5132fc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kirchhoff', \"'s\", 'Ġ', 'KVL', 'Ġstates', 'Ġthe', 'Ġsum', 'Ġof', 'Ġvolt', 'ages', 'Ġin', 'Ġa', 'Ġloop', 'Ġis', 'Ġzero', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization after adding domain-specific tokens\n",
    "print(tokenizer.tokenize(\"Kirchhoff's KVL states the sum of voltages in a loop is zero.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44d742",
   "metadata": {},
   "source": [
    "### Extending Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd786f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json: 100% [====================] 482/482 [00:00<00:00, 99.0kB/s]\n",
      "model.safetensors: 100% [====================] 1.42G/1.42G [00:07<00:00, 207MB/s]"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8368e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50267, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize the token embedding matrix to accommodate new tokens.\n",
    "# The model will initialize the new embeddings based on existing embeddings.\n",
    "# The model will learn about the new tokens during fine-tuning.\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf460c7",
   "metadata": {},
   "source": [
    "### Save Extended Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fab6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the tokenizer and model\n",
    "output_dir = f'{model_name.split(\"/\")[-1]}-extended-vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd10ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('roberta-large-extended-vocab/tokenizer_config.json',\n",
       " 'roberta-large-extended-vocab/special_tokens_map.json',\n",
       " 'roberta-large-extended-vocab/vocab.json',\n",
       " 'roberta-large-extended-vocab/merges.txt',\n",
       " 'roberta-large-extended-vocab/added_tokens.json',\n",
       " 'roberta-large-extended-vocab/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Tokenizer\n",
    "# New tokens will be saved in \"added_tokens.json\"\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e10850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
